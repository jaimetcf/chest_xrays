{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27349,
     "status": "ok",
     "timestamp": 1568836745422,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "jcrdKa3DlHfu",
    "outputId": "12840fbe-5fb7-4366-fc69-c9c73458e889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4XN2OZ6lPJB"
   },
   "outputs": [],
   "source": [
    "# IMPORTS LIBRARIES NEEDED #######################################################################\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from keras.applications import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINES SOME PARAMETERS ########################################################################\n",
    "\n",
    "train_path  = \"/content/drive/My Drive/ML/projects/chest_xray/images/train\"\n",
    "test_path   = \"/content/drive/My Drive/ML/projects/chest_xray/images/test\"\n",
    "val_path    = \"/content/drive/My Drive/ML/projects/chest_xray/images/val\"\n",
    "models_path = \"/content/drive/My Drive/ML/projects/chest_xray/cnn_models/\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "IM_HEIGHT = 200\n",
    "IM_WIDTH = 200\n",
    "\n",
    "NTRAIN_IMAGES = 5216\n",
    "NTEST_IMAGES = 624\n",
    "NVAL_IMAGES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1568755779045,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "88j2IDSie3GG",
    "outputId": "c1746ee2-1f6c-4308-afa2-ae78b60fb37f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# CREATES DATA GENERATORS FOR READING AND AUGMENTING IMAGES ######################################\n",
    "\n",
    "# The function ImageDataGenerator augments your image by iterating \n",
    "train_datagen = ImageDataGenerator(\n",
    "                                   preprocessing_function = preprocess_input,\n",
    "                                   rotation_range = 15,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   rescale = 1./255                           )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                   preprocessing_function = preprocess_input,\n",
    "                                   rescale = 1./255                           )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path,\n",
    "                                           target_size = (IM_HEIGHT, IM_WIDTH),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           class_mode = 'categorical')\n",
    "\n",
    "test_generator  = test_datagen.flow_from_directory( test_path,\n",
    "                                           target_size = (IM_HEIGHT, IM_WIDTH),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           class_mode = 'categorical')\n",
    "\n",
    "val_generator   = test_datagen.flow_from_directory( val_path,\n",
    "                                           target_size=(IM_HEIGHT, IM_WIDTH),\n",
    "                                           batch_size=1,\n",
    "                                           class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33788,
     "status": "ok",
     "timestamp": 1568755827216,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "0zOxf7JGiBJw",
    "outputId": "ed01704b-e7a0-46e2-fe16-e878ad8f6d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 200, 200, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 99, 99, 32)   864         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 99, 99, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 99, 99, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 97, 97, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 97, 97, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 97, 97, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 97, 97, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 97, 97, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 97, 97, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 97, 97, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 97, 97, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 49, 49, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 49, 49, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 49, 49, 128)  512         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_328 (Add)                   (None, 49, 49, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 49, 49, 128)  0           add_328[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 49, 49, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 49, 49, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 49, 49, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 49, 49, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 49, 49, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 25, 25, 256)  32768       add_328[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 25, 25, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 25, 25, 256)  1024        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_329 (Add)                   (None, 25, 25, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 25, 25, 256)  0           add_329[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 25, 25, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 25, 25, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 25, 25, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 25, 25, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 25, 25, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 13, 13, 728)  186368      add_329[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 13, 13, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 13, 13, 728)  2912        conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_330 (Add)                   (None, 13, 13, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 13, 13, 728)  0           add_330[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 13, 13, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 13, 13, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_331 (Add)                   (None, 13, 13, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_330[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 13, 13, 728)  0           add_331[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 13, 13, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 13, 13, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_332 (Add)                   (None, 13, 13, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_331[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 13, 13, 728)  0           add_332[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 13, 13, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 13, 13, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_333 (Add)                   (None, 13, 13, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_332[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 13, 13, 728)  0           add_333[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 13, 13, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 13, 13, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_334 (Add)                   (None, 13, 13, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_333[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 13, 13, 728)  0           add_334[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 13, 13, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 13, 13, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_335 (Add)                   (None, 13, 13, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_334[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_335[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 13, 13, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 13, 13, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_336 (Add)                   (None, 13, 13, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_335[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_336[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 13, 13, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 13, 13, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_337 (Add)                   (None, 13, 13, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_336[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_337[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 13, 13, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 13, 13, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_338 (Add)                   (None, 13, 13, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_337[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_338[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 13, 13, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 13, 13, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 13, 13, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 7, 7, 1024)   745472      add_338[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 7, 7, 1024)   4096        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_339 (Add)                   (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_339[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_22 (Gl (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1024)         2098176     global_average_pooling2d_22[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 1024)         4096        dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 2)            2050        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,965,802\n",
      "Trainable params: 22,909,226\n",
      "Non-trainable params: 56,576\n",
      "__________________________________________________________________________________________________\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d_112\n",
      "13 block2_pool\n",
      "14 batch_normalization_113\n",
      "15 add_328\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_113\n",
      "23 block3_pool\n",
      "24 batch_normalization_114\n",
      "25 add_329\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_114\n",
      "33 block4_pool\n",
      "34 batch_normalization_115\n",
      "35 add_330\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_331\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_332\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_333\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_334\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_335\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_336\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_337\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_338\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_115\n",
      "123 block13_pool\n",
      "124 batch_normalization_116\n",
      "125 add_339\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n",
      "132 global_average_pooling2d_22\n",
      "133 dense_60\n",
      "134 batch_normalization_117\n",
      "135 dropout_6\n",
      "136 dense_61\n"
     ]
    }
   ],
   "source": [
    "# CREATES THE CNN MODEL ##########################################################################\n",
    "\n",
    "#init = initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=1)\n",
    "input = layers.Input(shape=(IM_HEIGHT,IM_WIDTH,3)) \n",
    "\n",
    "conv1 = layers.convolutional.Conv2D( filters=64, kernel_size=(3,3),  \n",
    "                                     #activity_regularizer=regularizers.l2(0.01), \n",
    "                                     #use_bias=True,bias_initializer=init, \n",
    "                                     #kernel_initializer=init,\n",
    "                                     activation = 'relu')(input)\n",
    "pool1 = layers.MaxPooling2D((2,2))(conv1)\n",
    "batch1 = layers.BatchNormalization()(pool1)\n",
    "drop1 = layers.Dropout(0.2)(batch1)\n",
    "\n",
    "conv2 = layers.convolutional.Conv2D( filters=64, kernel_size=(3,3),  \n",
    "                                     #activity_regularizer=regularizers.l2(0.01), \n",
    "                                     #use_bias=True,bias_initializer=init, \n",
    "                                     #kernel_initializer=init,\n",
    "                                     activation = 'relu')(drop1) \n",
    "pool2 = layers.MaxPooling2D((2,2))(conv2)\n",
    "batch2 = layers.BatchNormalization()(pool2)\n",
    "drop2 = layers.Dropout(0.2)(batch2)\n",
    "\n",
    "conv3 = layers.convolutional.Conv2D( filters=128, kernel_size=(3,3),  \n",
    "                                     #activity_regularizer=regularizers.l2(0.01), \n",
    "                                     #use_bias=True,bias_initializer=init, \n",
    "                                     #kernel_initializer=init,\n",
    "                                     activation = 'relu')(drop2)\n",
    "pool3 = layers.MaxPooling2D((2,2))(conv3)\n",
    "batch3 = layers.BatchNormalization()(pool3)\n",
    "drop3 = layers.Dropout(0.2)(batch3)\n",
    "\n",
    "conv4 = layers.convolutional.Conv2D( filters=128, kernel_size=(3,3),  \n",
    "                                     #activity_regularizer=regularizers.l2(0.01), \n",
    "                                     #use_bias=True,bias_initializer=init, \n",
    "                                     #kernel_initializer=init,\n",
    "                                     activation = 'relu')(drop3) \n",
    "pool4 = layers.MaxPooling2D((2,2))(conv4)\n",
    "\n",
    "conv5 = layers.convolutional.Conv2D( filters=128, kernel_size=(3,3),activation='relu')(pool4)\n",
    "pool5 = layers.MaxPooling2D((2,2))(conv5)\n",
    "\n",
    "flat = layers.Flatten()(pool5)\n",
    "\n",
    "dense1 = layers.Dense( 8, \n",
    "                       #use_bias=True, bias_initializer=init, kernel_initializer=init,\n",
    "                       activation='relu')(flat) \n",
    "dense2 = layers.Dense( 1,\n",
    "                       #use_bias=True, bias_initializer=init, kernel_initializer=init,\n",
    "                       activation='sigmoid')(dense1)\n",
    "\n",
    "model = models.Model(inputs=input, outputs=dense2) \n",
    "optim = RMSprop(lr=0.0007) \n",
    "model.compile(optimizer=optim, loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4209677,
     "status": "ok",
     "timestamp": 1568760065477,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "WEcQ2bLk6kN7",
    "outputId": "9a299339-2916-48de-9f7f-28e02bdc6e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163/163 [==============================] - 228s 1s/step - loss: 0.3660 - acc: 0.8974 - val_loss: 9.9743 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.37500, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/xception.01-0.375.h5\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 197s 1s/step - loss: 0.1770 - acc: 0.9413 - val_loss: 8.2006 - val_acc: 0.4257\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.37500 to 0.42568, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/xception.02-0.426.h5\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - 197s 1s/step - loss: 0.1533 - acc: 0.9532 - val_loss: 2.4515 - val_acc: 0.8007\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.42568 to 0.80068, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/xception.03-0.801.h5\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 198s 1s/step - loss: 0.1159 - acc: 0.9647 - val_loss: 0.8603 - val_acc: 0.8361\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.80068 to 0.83615, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/xception.04-0.836.h5\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 197s 1s/step - loss: 0.0984 - acc: 0.9688 - val_loss: 1.9714 - val_acc: 0.7534\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.83615\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 197s 1s/step - loss: 0.0882 - acc: 0.9697 - val_loss: 1.3963 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.83615 to 0.87500, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/xception.06-0.875.h5\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 196s 1s/step - loss: 0.0823 - acc: 0.9757 - val_loss: 0.2117 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.87500 to 0.92230, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/xception.07-0.922.h5\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - 196s 1s/step - loss: 0.0629 - acc: 0.9760 - val_loss: 0.2593 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92230\n",
      "Epoch 9/20\n",
      "163/163 [==============================] - 196s 1s/step - loss: 0.0727 - acc: 0.9755 - val_loss: 0.5904 - val_acc: 0.8176\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92230\n",
      "Epoch 10/20\n",
      "163/163 [==============================] - 195s 1s/step - loss: 0.0670 - acc: 0.9749 - val_loss: 0.3570 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92230\n",
      "Epoch 11/20\n",
      "163/163 [==============================] - 195s 1s/step - loss: 0.0593 - acc: 0.9797 - val_loss: 0.3829 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92230\n",
      "Epoch 12/20\n",
      "163/163 [==============================] - 195s 1s/step - loss: 0.0575 - acc: 0.9814 - val_loss: 0.1641 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.92230 to 0.94088, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/xception.12-0.941.h5\n",
      "Epoch 13/20\n",
      "163/163 [==============================] - 197s 1s/step - loss: 0.0499 - acc: 0.9831 - val_loss: 0.4879 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94088\n",
      "Epoch 14/20\n",
      "163/163 [==============================] - 197s 1s/step - loss: 0.0529 - acc: 0.9812 - val_loss: 0.8177 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94088\n",
      "Epoch 15/20\n",
      "163/163 [==============================] - 197s 1s/step - loss: 0.0543 - acc: 0.9831 - val_loss: 0.4694 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94088\n",
      "Epoch 16/20\n",
      "163/163 [==============================] - 196s 1s/step - loss: 0.0534 - acc: 0.9820 - val_loss: 0.6699 - val_acc: 0.8007\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94088\n",
      "Epoch 17/20\n",
      "163/163 [==============================] - 196s 1s/step - loss: 0.0443 - acc: 0.9885 - val_loss: 0.3611 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.94088\n",
      "Epoch 18/20\n",
      "163/163 [==============================] - 196s 1s/step - loss: 0.0545 - acc: 0.9864 - val_loss: 1.1153 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.94088\n",
      "Epoch 19/20\n",
      "163/163 [==============================] - 195s 1s/step - loss: 0.0391 - acc: 0.9866 - val_loss: 0.3252 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.94088\n",
      "Epoch 20/20\n",
      "163/163 [==============================] - 195s 1s/step - loss: 0.0321 - acc: 0.9916 - val_loss: 0.5998 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.94088\n"
     ]
    }
   ],
   "source": [
    "# TRAINS THE MODEL ###############################################################################\n",
    "\n",
    "# Configures callback function for saving the model when val_acc improves\n",
    "h5_filepath = models_path + \"conv4d2.{epoch:02d}-{val_acc:.3f}.h5\"\n",
    "checkpoint = ModelCheckpoint( h5_filepath, monitor='val_acc', verbose=1, \n",
    "                              save_best_only=True, \n",
    "                              save_weights_only=False, \n",
    "                              mode='auto', \n",
    "                              period=1)  # number of epochs between checkpoints\n",
    "\n",
    "# Configures callback to stop training when val_acc stops improving\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, \n",
    "#                       mode='auto')\n",
    "#callbacks_list = [checkpoint, early]\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Runs training\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = NTRAIN_IMAGES // BATCH_SIZE,\n",
    "                              epochs = 50,\n",
    "                              validation_data = test_generator,\n",
    "                              validation_steps = NTEST_IMAGES // BATCH_SIZE,\n",
    "                              #shuffle = True, \n",
    "                              callbacks = callbacks_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1568761395429,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "JZGzp8DvjEKZ",
    "outputId": "ee45a717-2fea-4573-f4e7-937236d88fa6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOTS TRAINING RESULTS \n",
    "\n",
    "# Plots history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#pred = model.predict(test_set)\n",
    "#print(classification_report(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mRVlXl0YOj2"
   },
   "outputs": [],
   "source": [
    "model_path = \"/content/drive/My Drive/ML/projects/chest_xray/cnn_models/cxrays_conv4d2.h5\"\n",
    "\n",
    "model.save_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5216,
     "status": "ok",
     "timestamp": 1568760392173,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "tMh5Ocj9dPXi",
    "outputId": "af38cec3-3480-4ef7-f001-1a07dae7601e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6064742734051833, 0.8125]"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate_generator(val_generator, verbose=2)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "de9bzZUipdPx"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.grid(b=False)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1085,
     "status": "error",
     "timestamp": 1568584769051,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "p0KAz3fNpfKh",
    "outputId": "b7884f4d-aaec-4762-c028-115daa47d305"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0efd4189cd98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m plot_confusion_matrix(cm = cm,\n\u001b[1;32m      4\u001b[0m                       \u001b[0mnormalize\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'Reds'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_valid' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1))\n",
    "plot_confusion_matrix(cm = cm,\n",
    "                      normalize    = False,\n",
    "                      cmap ='Reds',\n",
    "                      target_names = ['0','1'],\n",
    "                      title        = \"Confusion Matrix\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chest_xray_xception.ipynb",
   "provenance": [
    {
     "file_id": "11-_85rmydNrGsTlqmFcADrbD6VX7wvyY",
     "timestamp": 1568723680886
    },
    {
     "file_id": "14NcDx3c8ZeygnAF49dRWoDZ6wuBqORou",
     "timestamp": 1568640275604
    },
    {
     "file_id": "1cnPoANs2Zxt5HnGuLNACXXu2IeQOxTQN",
     "timestamp": 1568594148501
    },
    {
     "file_id": "1pjS0WP_vaM5gjT6RtoHxUQB0M8RiWfT1",
     "timestamp": 1568308527292
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
