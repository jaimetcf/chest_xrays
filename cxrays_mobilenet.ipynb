{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25016,
     "status": "ok",
     "timestamp": 1569104603970,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "jcrdKa3DlHfu",
    "outputId": "88b423d3-9722-43fe-a178-fc42c60d59d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# MOUNTS GOOGLE DRIVE ##########################################################################\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2078,
     "status": "ok",
     "timestamp": 1568923490819,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "f4XN2OZ6lPJB",
    "outputId": "742d4b0b-af23-431d-a486-bc8bf8d31f45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS LIBRARIES NEEDED #######################################################################\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5g_DxvMj9uK2"
   },
   "outputs": [],
   "source": [
    "# DEFINES SOME PARAMETERS ########################################################################\n",
    "\n",
    "train_path  = \"/content/drive/My Drive/ML/projects/chest_xray/images/train\"\n",
    "test_path   = \"/content/drive/My Drive/ML/projects/chest_xray/images/test\"\n",
    "val_path    = \"/content/drive/My Drive/ML/projects/chest_xray/images/val\"\n",
    "models_path = \"/content/drive/My Drive/ML/projects/chest_xray/cnn_models/\"\n",
    "\n",
    "#model_file_name =\"xception.06-0.875.h5\"\n",
    "#model_file_name =\"xception.15-0.938.h5\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "IM_HEIGHT = 200\n",
    "IM_WIDTH = 200\n",
    "\n",
    "NTRAIN_IMAGES = 5216\n",
    "NTEST_IMAGES = 624\n",
    "NVAL_IMAGES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1568923652926,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "88j2IDSie3GG",
    "outputId": "f2ea93fc-b4df-4fd7-dfeb-d31a90e76a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# CREATES DATA GENERATORS FOR READING AND AUGMENTING IMAGES ######################################\n",
    "\n",
    "# The train generator will rotate, shift verticaly and horizontaly, zoom, shrink, \n",
    "# and flip images horizontally\n",
    "train_datagen = ImageDataGenerator(\n",
    "                                   preprocessing_function = preprocess_input,\n",
    "                                   rotation_range = 15,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   rescale = 1./255                           )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                   preprocessing_function = preprocess_input,\n",
    "                                   rescale = 1./255                           )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path,\n",
    "                                           target_size = (IM_HEIGHT, IM_WIDTH),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           class_mode = 'categorical')\n",
    "\n",
    "test_generator  = test_datagen.flow_from_directory( test_path,\n",
    "                                           target_size = (IM_HEIGHT, IM_WIDTH),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           class_mode = 'categorical')\n",
    "\n",
    "val_generator   = test_datagen.flow_from_directory( val_path,\n",
    "                                           target_size=(IM_HEIGHT, IM_WIDTH),\n",
    "                                           batch_size=1,\n",
    "                                           class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6172,
     "status": "ok",
     "timestamp": 1568923662276,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "0zOxf7JGiBJw",
    "outputId": "5578588f-fe15-4387-97fe-d4d3082148f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 201, 201, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 100, 100, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 100, 100, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 100, 100, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 100, 100, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 101, 101, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 50, 50, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 50, 50, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 50, 50, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 50, 50, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 50, 50, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 50, 50, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 50, 50, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 51, 51, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 25, 25, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 25, 25, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 25, 25, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 25, 25, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 25, 25, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 25, 25, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 25, 25, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 12, 12, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 12, 12, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 12, 12, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 12, 12, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 12, 12, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 12, 12, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 12, 12, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 12, 12, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 12, 12, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 12, 12, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 12, 12, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 12, 12, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 6, 6, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 6, 6, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 6, 6, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 4,284,610\n",
      "Trainable params: 4,260,674\n",
      "Non-trainable params: 23,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CREATES THE MOBILENET MODEL #########################################################################\n",
    "\n",
    "base_model = MobileNet(weights ='imagenet', \n",
    "                      include_top = False,\n",
    "                      input_shape = ( IM_HEIGHT, IM_WIDTH, 3) )\n",
    "\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "predictions = layers.Dense( 2, activation='softmax')(x)\n",
    "\n",
    "model = models.Model( inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# TRANSFER LEARNING -> This is commented because Transfer Learning produced worse results when\n",
    "# compared to full training\n",
    "# Freezes weights of model from block1 until block5\n",
    "#for layer in base_model.layers[:46]:    layer.trainable=False\n",
    "#for layer in base_model.layers[46:]:    layer.trainable=True\n",
    "\n",
    "#model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#optim = RMSprop(lr=0.0007) \n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Prints full model layers\n",
    "#for i,layer in enumerate(model.layers):  \n",
    "#  if(layer.trainable == True): print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12657627,
     "status": "ok",
     "timestamp": 1568936348457,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "WEcQ2bLk6kN7",
    "outputId": "b5b587aa-0972-4790-d63c-57c40e53f31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "163/163 [==============================] - 1440s 9s/step - loss: 0.3424 - acc: 0.9103 - val_loss: 0.3108 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89967, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/mobilenet.01-0.8997.h5\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 111s 682ms/step - loss: 0.1668 - acc: 0.9431 - val_loss: 3.8016 - val_acc: 0.4476\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89967\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 111s 681ms/step - loss: 0.1271 - acc: 0.9557 - val_loss: 1.5551 - val_acc: 0.6892\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89967\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 111s 681ms/step - loss: 0.1066 - acc: 0.9634 - val_loss: 1.9774 - val_acc: 0.6791\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89967\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 111s 682ms/step - loss: 0.1051 - acc: 0.9643 - val_loss: 2.3119 - val_acc: 0.6047\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89967\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 111s 680ms/step - loss: 0.0882 - acc: 0.9695 - val_loss: 1.6062 - val_acc: 0.6858\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89967\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 112s 686ms/step - loss: 0.0802 - acc: 0.9709 - val_loss: 0.1632 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.89967 to 0.93919, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/mobilenet.07-0.9392.h5\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 112s 690ms/step - loss: 0.0822 - acc: 0.9739 - val_loss: 0.3367 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93919\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 112s 685ms/step - loss: 0.0629 - acc: 0.9795 - val_loss: 0.3181 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93919\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 109s 672ms/step - loss: 0.0591 - acc: 0.9795 - val_loss: 1.3002 - val_acc: 0.6740\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93919\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 112s 687ms/step - loss: 0.0586 - acc: 0.9801 - val_loss: 0.6644 - val_acc: 0.8361\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93919\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 111s 683ms/step - loss: 0.0644 - acc: 0.9780 - val_loss: 0.7866 - val_acc: 0.8378\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93919\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 111s 683ms/step - loss: 0.0656 - acc: 0.9781 - val_loss: 0.4212 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93919\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 113s 691ms/step - loss: 0.0525 - acc: 0.9806 - val_loss: 0.7220 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93919\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 113s 694ms/step - loss: 0.0516 - acc: 0.9816 - val_loss: 0.4572 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93919\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 112s 686ms/step - loss: 0.0494 - acc: 0.9841 - val_loss: 0.2354 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93919\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 111s 682ms/step - loss: 0.0502 - acc: 0.9818 - val_loss: 0.2104 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93919\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 112s 686ms/step - loss: 0.0441 - acc: 0.9831 - val_loss: 0.2521 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93919\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 113s 692ms/step - loss: 0.0403 - acc: 0.9864 - val_loss: 0.2783 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93919\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 112s 689ms/step - loss: 0.0417 - acc: 0.9847 - val_loss: 0.3181 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93919\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 113s 695ms/step - loss: 0.0432 - acc: 0.9866 - val_loss: 0.2238 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93919\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 116s 709ms/step - loss: 0.0434 - acc: 0.9862 - val_loss: 0.4367 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93919\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 109s 672ms/step - loss: 0.0378 - acc: 0.9877 - val_loss: 0.2427 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.93919\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 111s 680ms/step - loss: 0.0517 - acc: 0.9852 - val_loss: 0.2572 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93919\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 112s 689ms/step - loss: 0.0335 - acc: 0.9891 - val_loss: 0.6537 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93919\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 113s 693ms/step - loss: 0.0358 - acc: 0.9902 - val_loss: 0.4288 - val_acc: 0.8986\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.93919\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 113s 695ms/step - loss: 0.0437 - acc: 0.9864 - val_loss: 0.2044 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.93919\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 113s 691ms/step - loss: 0.0311 - acc: 0.9900 - val_loss: 0.4758 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.93919\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 111s 683ms/step - loss: 0.0368 - acc: 0.9864 - val_loss: 0.2890 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.93919\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 113s 691ms/step - loss: 0.0360 - acc: 0.9889 - val_loss: 0.3391 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93919\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 112s 690ms/step - loss: 0.0333 - acc: 0.9902 - val_loss: 0.3192 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.93919\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 113s 691ms/step - loss: 0.0275 - acc: 0.9895 - val_loss: 0.5907 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93919\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 112s 688ms/step - loss: 0.0377 - acc: 0.9883 - val_loss: 0.3588 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.93919\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 112s 686ms/step - loss: 0.0310 - acc: 0.9887 - val_loss: 0.1801 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.93919 to 0.94257, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/mobilenet.34-0.9426.h5\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 112s 688ms/step - loss: 0.0287 - acc: 0.9895 - val_loss: 0.3206 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.94257\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 113s 692ms/step - loss: 0.0220 - acc: 0.9923 - val_loss: 0.2044 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.94257\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 113s 695ms/step - loss: 0.0279 - acc: 0.9914 - val_loss: 0.2569 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.94257\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 113s 692ms/step - loss: 0.0373 - acc: 0.9906 - val_loss: 0.5484 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.94257\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 113s 695ms/step - loss: 0.0257 - acc: 0.9910 - val_loss: 0.2869 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.94257\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 111s 683ms/step - loss: 0.0227 - acc: 0.9935 - val_loss: 0.8494 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.94257\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 112s 689ms/step - loss: 0.0343 - acc: 0.9895 - val_loss: 0.4144 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.94257\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 117s 715ms/step - loss: 0.0264 - acc: 0.9916 - val_loss: 0.3999 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.94257\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 111s 681ms/step - loss: 0.0261 - acc: 0.9923 - val_loss: 0.2396 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.94257\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 110s 676ms/step - loss: 0.0224 - acc: 0.9921 - val_loss: 0.9474 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.94257\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 110s 677ms/step - loss: 0.0221 - acc: 0.9925 - val_loss: 0.3176 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.94257\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 113s 693ms/step - loss: 0.0218 - acc: 0.9914 - val_loss: 0.2707 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.94257\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 112s 685ms/step - loss: 0.0237 - acc: 0.9918 - val_loss: 0.9208 - val_acc: 0.8057\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.94257\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 112s 690ms/step - loss: 0.0196 - acc: 0.9933 - val_loss: 0.4598 - val_acc: 0.8986\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.94257\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 112s 686ms/step - loss: 0.0308 - acc: 0.9887 - val_loss: 0.3991 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.94257\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 113s 693ms/step - loss: 0.0248 - acc: 0.9925 - val_loss: 0.3705 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.94257\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 112s 689ms/step - loss: 0.0306 - acc: 0.9906 - val_loss: 0.2416 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.94257\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 113s 694ms/step - loss: 0.0237 - acc: 0.9929 - val_loss: 0.1981 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.94257\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 111s 682ms/step - loss: 0.0201 - acc: 0.9946 - val_loss: 0.2716 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.94257\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 112s 690ms/step - loss: 0.0213 - acc: 0.9929 - val_loss: 0.2785 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.94257\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 113s 695ms/step - loss: 0.0247 - acc: 0.9925 - val_loss: 0.3208 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.94257\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 114s 697ms/step - loss: 0.0243 - acc: 0.9931 - val_loss: 0.3894 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.94257\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 112s 687ms/step - loss: 0.0179 - acc: 0.9937 - val_loss: 0.4921 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.94257\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 114s 698ms/step - loss: 0.0179 - acc: 0.9933 - val_loss: 0.2566 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.94257\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 113s 692ms/step - loss: 0.0208 - acc: 0.9929 - val_loss: 0.2882 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.94257\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 111s 683ms/step - loss: 0.0169 - acc: 0.9946 - val_loss: 0.3197 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.94257\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 111s 684ms/step - loss: 0.0235 - acc: 0.9946 - val_loss: 0.3318 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.94257\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 116s 713ms/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.4980 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.94257\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 111s 678ms/step - loss: 0.0200 - acc: 0.9946 - val_loss: 0.3557 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.94257\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 111s 682ms/step - loss: 0.0157 - acc: 0.9956 - val_loss: 0.3274 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.94257\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 111s 682ms/step - loss: 0.0228 - acc: 0.9931 - val_loss: 0.2876 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.94257\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 113s 693ms/step - loss: 0.0140 - acc: 0.9958 - val_loss: 0.3378 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.94257\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 116s 712ms/step - loss: 0.0120 - acc: 0.9967 - val_loss: 0.4506 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.94257\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 114s 699ms/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.4055 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.94257\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 115s 707ms/step - loss: 0.0226 - acc: 0.9919 - val_loss: 0.3295 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.94257\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 114s 698ms/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.2791 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.94257\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 115s 703ms/step - loss: 0.0177 - acc: 0.9954 - val_loss: 0.4692 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.94257\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 115s 706ms/step - loss: 0.0179 - acc: 0.9958 - val_loss: 0.4804 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.94257\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 114s 699ms/step - loss: 0.0190 - acc: 0.9935 - val_loss: 0.4576 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.94257\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 114s 702ms/step - loss: 0.0197 - acc: 0.9931 - val_loss: 0.4769 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.94257\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 114s 702ms/step - loss: 0.0207 - acc: 0.9944 - val_loss: 0.2437 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.94257 to 0.94595, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/mobilenet.75-0.9459.h5\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 116s 709ms/step - loss: 0.0121 - acc: 0.9960 - val_loss: 0.3176 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.94595\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 116s 712ms/step - loss: 0.0171 - acc: 0.9941 - val_loss: 0.2486 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.94595\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 116s 712ms/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.2196 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.94595\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 117s 720ms/step - loss: 0.0154 - acc: 0.9952 - val_loss: 0.3565 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.94595\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 116s 713ms/step - loss: 0.0151 - acc: 0.9937 - val_loss: 0.2463 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.94595\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 116s 711ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.3074 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.94595 to 0.94737, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/mobilenet.81-0.9474.h5\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 120s 737ms/step - loss: 0.0188 - acc: 0.9946 - val_loss: 0.5349 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.94737\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 115s 704ms/step - loss: 0.0175 - acc: 0.9958 - val_loss: 0.2848 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.94737\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 114s 701ms/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.3983 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.94737\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 118s 723ms/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.3861 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.94737\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 116s 713ms/step - loss: 0.0089 - acc: 0.9983 - val_loss: 0.4168 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.94737\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 115s 707ms/step - loss: 0.0147 - acc: 0.9952 - val_loss: 0.6810 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.94737\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 117s 717ms/step - loss: 0.0253 - acc: 0.9929 - val_loss: 0.3867 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.94737\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 114s 697ms/step - loss: 0.0168 - acc: 0.9941 - val_loss: 0.3992 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.94737\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 115s 705ms/step - loss: 0.0130 - acc: 0.9952 - val_loss: 0.6268 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.94737\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 114s 698ms/step - loss: 0.0143 - acc: 0.9948 - val_loss: 0.5663 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.94737\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 113s 692ms/step - loss: 0.0160 - acc: 0.9946 - val_loss: 0.3667 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.94737\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 114s 700ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.4495 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.94737\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 113s 690ms/step - loss: 0.0126 - acc: 0.9971 - val_loss: 0.3121 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.94737 to 0.94932, saving model to /content/drive/My Drive/ML/projects/chest_xray/cnn_models/mobilenet.94-0.9493.h5\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 113s 694ms/step - loss: 0.0148 - acc: 0.9956 - val_loss: 0.3639 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.94932\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 114s 700ms/step - loss: 0.0136 - acc: 0.9950 - val_loss: 0.4997 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.94932\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 115s 705ms/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.2661 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.94932\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 113s 696ms/step - loss: 0.0139 - acc: 0.9952 - val_loss: 0.2991 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.94932\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 113s 692ms/step - loss: 0.0157 - acc: 0.9965 - val_loss: 0.2597 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.94932\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 113s 692ms/step - loss: 0.0088 - acc: 0.9969 - val_loss: 0.5014 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.94932\n"
     ]
    }
   ],
   "source": [
    "# TRAINS THE MODEL (FULL) ############################################################################\n",
    "\n",
    "# Configures callback function for saving the model when val_acc improves\n",
    "h5_filepath = models_path + \"mobilenet.{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint( h5_filepath, monitor='val_accuracy', verbose=1, \n",
    "                              save_best_only=True, \n",
    "                              save_weights_only=False, \n",
    "                              mode='auto', \n",
    "                              period=1)  # number of epochs between checkpoints\n",
    "\n",
    "# Configures callback to stop training when val_acc stops improving\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, \n",
    "#                       mode='auto')\n",
    "#callbacks_list = [checkpoint, early]\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = NTRAIN_IMAGES // BATCH_SIZE,\n",
    "                              epochs = 100,\n",
    "                              validation_data = test_generator,\n",
    "                              validation_steps = NTEST_IMAGES // BATCH_SIZE,\n",
    "                              #shuffle = True, \n",
    "                              callbacks = callbacks_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1568936364992,
     "user": {
      "displayName": "Jaime Santo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBmyV7-C_c1EyNHrDc0gsu0VHqVslOzG8yEXsRv=s64",
      "userId": "17913989483502775130"
     },
     "user_tz": 180
    },
    "id": "JZGzp8DvjEKZ",
    "outputId": "466e55aa-4df0-4972-c782-2efa09031fd7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOTS TRAINING RESULTS ###############################################################################\n",
    "\n",
    "# Plots history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#pred = model.predict(test_set)\n",
    "#print(classification_report(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mRVlXl0YOj2"
   },
   "outputs": [],
   "source": [
    "model_path = \"/content/drive/My Drive/ML/projects/chest_xray/cnn_models/chest_xray_mobilenet.h5\"\n",
    "\n",
    "model.save_weights(model_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chest_xray_mobilenet.ipynb",
   "provenance": [
    {
     "file_id": "1LVf1_PlXf0CiIuexx8nxe4CfPp5QiGux",
     "timestamp": 1568836755860
    },
    {
     "file_id": "11-_85rmydNrGsTlqmFcADrbD6VX7wvyY",
     "timestamp": 1568723680886
    },
    {
     "file_id": "14NcDx3c8ZeygnAF49dRWoDZ6wuBqORou",
     "timestamp": 1568640275604
    },
    {
     "file_id": "1cnPoANs2Zxt5HnGuLNACXXu2IeQOxTQN",
     "timestamp": 1568594148501
    },
    {
     "file_id": "1pjS0WP_vaM5gjT6RtoHxUQB0M8RiWfT1",
     "timestamp": 1568308527292
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
